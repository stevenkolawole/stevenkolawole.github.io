<!DOCTYPE html>
<html>
  <head>
    <title>Steven's Publications</title>
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=Overpass+Mono:wght@300;400;600;700&display=swap"
      rel="stylesheet"
    />
    <link
      rel="stylesheet"
      href="https://use.fontawesome.com/releases/v5.0.7/css/all.css"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
  </head>

  <body>
    <header class="site-header">
      <nav class="nav">
        <div class="container flex-wrap">
          <h1 class="logo">
            <a href="https://stevenkolawole.github.io/">Steven Kolawole</a>
          </h1>
          <ul class="navbar">
            <li><a href="index.html">About</a></li>
            <li><a href="publications.html" class="active">Publications</a></li>
            <li><a href="news.html">Recent Highlights</a></li>
            <li><a href="blog.html">Blog</a></li>
            <li><a href="assets/Steven_Kolawole_CV.pdf" target="_blank">CV</a></li>
          </ul>
        </div>
      </nav>
    </header>

    <div class="page container">
      <h1 class="header-name">Publications</h1>
      
      <div class="publications-intro" style="text-align: justify">
        <p>My research on ML systems efficiency spans three main areas: 
          developing efficient inference methods, addressing resource constraints 
        in multilingual settings, and building practical applications for social impact.</p>
      </div>

      <!-- Efficient ML & Systems -->
      <div class="publication-category">
        <h2 class="category-title">ML Efficiency & Systems</h2>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2402.05406" target="_blank">Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes</a>
              <!-- <span class="award-badge">Best Paper</span> -->
          </div>
          <div class="pub-authors"><span class="author-highlight">Steven Kolawole</span>*, Lucio Dery*, Jean-François Kagy, Virginia Smith, Graham Neubig, Ameet Talwalkar</div>
          <div class="pub-venue" title="Transactions of Machine Learning Research">under review</div>
          <div class="pub-description">
            Presents Bonsai, a forward-pass-only structured pruning method that outperforms gradient-based approaches 
            while using 3× less memory, making model compression accessible on everyday hardware.
          </div>
          <div class="pub-links">
            <!-- <a href="https://arxiv.org/abs/2402.05406" target="_blank" class="pub-link">
              <i class="fas fa-file-pdf"></i> Paper
            </a>
            <a href="https://yourblog.com/post-url" target="_blank" class="pub-link">
              <i class="fas fa-blog"></i> Blog
            </a> -->
            <a href="https://github.com/ldery/bonsai" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
          </div>
        </div>
      </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://openreview.net/forum?id=2uMRHHzAIJ" target="_blank">PRIVACYBENCH: Privacy Isn't Free in Hybrid Privacy-Preserving Vision Systems</a>
          </div>
          <div class="pub-authors">Nnaemeka Obiefuna, Samuel Oyeneye, Similoluwa Odunaiya, Iremide Oyelaja, <span class="author-highlight">Steven Kolawole</span></div>
          <div class="pub-venue" title="IEEE/CVF Winter Conference on Applications of Computer Vision">under review</div>
          <div class="pub-description">
            Comprehensive benchmarking study examining the computational/energy overhead of privacy-preserving techniques 
            in privacy-sensitive deep learning systems; conducted with independent student researchers at ML Collective.
          </div>
          <div class="pub-links">
            <a href="https://github.com/federated-learning-mlc/privacybench-exp" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
          </div>
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2506.18728" target="_blank">PARALLELPROMPT: Extracting Parallelism from Large Language Model Queries</a>
          </div>
          <div class="pub-authors"><span class="author-highlight">Steven Kolawole</span>, Keshav Santhanam, Virginia Smith, Pratiksha Thaker</div>
          <div class="pub-venue" title="Conference on Neural Information Processing Systems">NeurIPS 2025 Datasets & Benchmarks Track</div>
          <div class="pub-description">
            Introduces PARALLELPROMPT, a benchmark revealing that 10% of natural user queries contain latent parallelism. 
            Demonstrates semantic decomposition methods achieving up to 5× speedups without hardware modifications.
          </div>
          <div class="pub-links">
            <a href="https://github.com/stevenkolawole/ParallelPrompt" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
          <a href="https://huggingface.co/datasets/forgelab/parallelprompt" target="_blank" class="pub-link">
            <i class="fas fa-database"></i> Dataset
          </a>
          </div>
        </div>
        
        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2509.21837" target="_blank">Semantic Agreement Enables Efficient Open-Ended LLM Cascades</a>
          </div>
          <div class="pub-authors">Duncan Soiffer, <span class="author-highlight">Steven Kolawole</span>, Virginia Smith</div>
          <div class="pub-venue" title="Conference on Empirical Methods in Natural Language Processing">EMNLP 2025 Industry Track</div>
          <div class="pub-description">
            Extends agreement-based cascading to open-ended generation tasks, leveraging meaning-level consensus for cost-effective
            routing of language model queries without requiring additional training data or model modifications.
          </div>
          <!-- <div class="pub-links">
            <a href="https://github.com/ldery/bonsai" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
          </div> -->
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2407.02348" target="_blank">Agreement-Based Cascading for Efficient Inference</a>
          </div>
          <div class="pub-authors"><span class="author-highlight">Steven Kolawole</span>*, Don Dennis*, Ameet Talwalkar, Virginia Smith</div>
          <div class="pub-venue" title="Transactions of Machine Learning Research">TMLR 2025</div>
          <div class="pub-description">
            Develops a training-free cascading framework using ensemble agreement as a confidence signal for routing. 
            Achieves 2-25× cost reductions while maintaining/improving accuracy over diverse tasks.
          </div>
          <div class="pub-links">
            <a href="https://github.com/stevenkolawole/Agreement-Based-Cascading" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
          </div>
        </div>

      <!-- Resource-Constrained NLP -->
      <div class="publication-category">
        <h2 class="category-title">Resource-Constrained NLP</h2>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2509.07471" target="_blank">From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation</a>
          </div>
          <div class="pub-authors">Mardiyyah Oduwole, Oluwatosin Olajide, Jamiu Suleiman, Faith Hunja, Busayo Awobade, Fatimo Adebanjo, Comfort Akanni, Chinonyelum Igwe, Peace Ododo, Promise Omoigui, Steven Kolawole, Abraham Owodunni</div>
          <div class="pub-venue">arXiv preprint, 2023</div>
          <div class="pub-description">
            Comprehensive study on data augmentation techniques for African languages, showing that methods like back-translation and
            token replacement can significantly improve translation quality in low-resource settings.
          </div>
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2404.04759" target="_blank">What Happens When Small Is Made Smaller? Exploring the Impact of Compression on Small Data Pretrained Language Models</a>
          </div>
          <div class="pub-authors">Busayo Awobade*, Mardiyyah Oduwole*, <span class="author-highlight">Steven Kolawole</span>*</div>
          <div class="pub-venue">ICLR 2024 (AfricaNLP)</div>
          <div class="pub-description">
            Investigates compression techniques on AfriBERTa, demonstrating that pruning, knowledge distillation, 
            and quantization remain effective in the "low-resource double-bind" of small-data language models.
          </div>
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2303.16985" target="_blank">Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages</a>
          </div>
          <div class="pub-authors">Colin Leong, Herumb Shandilya, Bonaventure Dossou, Atnafu Tonja, Joel Mathew, Abdul-Hakeem Omotayo, Oreen Yousuf, Zainab Akinjobi, Chris Emezue, Shamsudeen Muhammad, Steven Kolawole, Younwoo Choi, Tosin Adewumi</div>
          <div class="pub-venue">ICLR 2023 (AfricaNLP)</div>
          <div class="pub-description">
            Explores efficient training methods for African language processing under computational constraints, 
            addressing the challenge of limited data and limited compute resources simultaneously.
          </div>
        </div>
      </div>

      <!-- Applied ML & Social Good -->
      <div class="publication-category">
        <h2 class="category-title">Applied ML & Social Good</h2>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://arxiv.org/abs/2305.19365" target="_blank">Vision Transformers for Mobile Applications: A Short Survey</a>
          </div>
          <div class="pub-authors">Nahid Alam*, <span class="author-highlight">Steven Kolawole</span>*, Simardeep Sethi*, Nishant Bansali, Karina Nguyen</div>
          <div class="pub-venue">arXiv preprint, 2023</div>
          <div class="pub-description">
            Comprehensive survey examining how Vision Transformers can be optimized for mobile deployment, 
            analyzing architecture modifications and efficiency techniques for resource-constrained environments.
          </div>
        </div>

        <div class="publication-item">
          <div class="pub-title">
            <a href="https://www.ijcai.org/proceedings/2022/855" target="_blank">Sign-to-Speech Model for Sign Language Understanding: A Case Study of Nigerian Sign Language</a>
          </div>
          <div class="pub-authors"><span class="author-highlight">Steven Kolawole</span>, Opeyemi Osakuade, Nayan Saxena, Babatunde Kazeem Olorisade</div>
          <div class="pub-venue" title="International Joint Conference on Artificial Intelligence">IJCAI 2022 AI for Social Good Track</div>
          <div class="pub-description">
            Develops a sign-to-speech system for Nigerian Sign Language to bridge communication gaps, combining computer vision and NLP techniques to translate sign language videos into spoken language.
            This work earned a bunch of local awards (including the national AI Champion award from the Nigeria Computer Society), demonstrating practical AI for social impact.
          </div>
          <div class="pub-links">
            <a href="https://github.com/ML-Collective/Sign-to-Speech-for-Sign-Language-Understanding" target="_blank" class="pub-link">
              <i class="fab fa-github"></i> Code
            </a>
            <a href="https://aihub.org/2022/10/12/interview-with-steven-kolawole-a-sign-to-speech-model-for-nigerian-sign-language/" target="_blank" class="pub-link">
              <i class="fas fa-newspaper"></i> Media
            </a>
          </div>
        </div>
      </div>

      <!-- External Links -->
      <div class="external-links">
        <h2 class="category-title">External Profiles</h2>
        <div class="external-link-list">
          <a href="https://scholar.google.com/citations?user=cekASD4AAAAJ&hl=en" target="_blank" class="external-link">
            <i class="ai ai-google-scholar"></i> Google Scholar Profile
          </a>
          <a href="https://openreview.net/profile?id=~Steven_Kolawole1" target="_blank" class="external-link">
            <i class="fas fa-file-alt"></i> OpenReview Profile
          </a>
          <a href="https://arxiv.org/search/?query=Kolawole%2C+Steven&searchtype=author" target="_blank" class="external-link">
            <i class="fas fa-archive"></i> arXiv Papers
          </a>
        </div>
      </div>

      <div class="publications-note">
        <p><small>* denotes equal contribution</small></p>
        <p><small>This list includes peer-reviewed publications, workshop papers, and preprints. 
        For the most up-to-date list with citation counts, please visit my Google Scholar profile.</small></p>
      </div>

    </div>
  </body>
</html>